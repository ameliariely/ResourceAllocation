"scales","e1071","phyclust")
sapply(pack.names,library,character.only=TRUE)
## Defined function
mode <- function(x)
{
tabSmpl<-tabulate(x)
ifelse((sum(tabSmpl == max(tabSmpl))>1),ceiling(mean(x)),which(tabSmpl== max(tabSmpl)))
}
rescale <- function(x)
{
value <- ifelse(x==1|x==2,1,ifelse(x==3,2,3))
return(value)
}
as.dummy <- function(x)
{
if(x==1)
{
value <- c(1,0,0)
}
else if(x==2)
{
value <- c(0,1,0)
}
else
{
value <- c(0,0,1)
}
return(value)
}
rvi <- function(x)
{
center <- ifelse(is.na(mode(x)),ceiling(mean(x)),mode(x))
value <- mean((x-center)^2)
return(value)
}
label.selector <- function(x,index)
{
x <- as.vector(t(x))
value <- x[seq(0,4*(length(index)-1),4)+index]
return(value)
}
iter.mean.calculator <- function(x,iter.index)
{
if(iter.index==4) iter.index <-0
x <- x[(x[,1] %% 4)==iter.index,]
value <- apply(x,2,mean)
return(value)
}
iter.rand.ci.calculator <- function(x,iter.index)
{
if(iter.index==4) iter.index <- 0
x <- x[(x[,1] %% 4)==iter.index,]
value <- as.vector(t.test(x[,3])$conf.int)
return(value)
}
iter.kappa.ci.calculator <- function(x,iter.index)
{
if(iter.index==4) iter.index <- 0
x <- x[(x[,1] %% 4)==iter.index,]
value <- as.vector(t.test(x[,4])$conf.int)
return(value)
}
##Absolutely necessary to run initialization BEFORE this file
##Import data
data <- read.csv("LIDC dataset with full annotations.csv",header=TRUE)
img_fs <- data[,c(5:18, 43:69)]
img_fs <- data.frame(img_fs, Avg.Gabor(data))
#Df for results
col <-  c("Mode 1", "Mode 2", "Mode 3", "Max Mode", "Set",
"I1 Label", "I1 Pred", "I1 Label Num", "I2 Label",
"I2 Pred","I2 Label Num", "I3 Label", "I3 Pred",
"I3 Label Num", "I4 Label", "I4 Pred", "A1.Pred",
"A2.Pred","A3.Pred","A4.Pred")
cont = rpart.control(minsplit = 250, minbucket= 58, maxdepth = 5)
t = 20
pb <- txtProgressBar(min = 0, max = t, style = 3)
allaccs <- vector(mode="list",length=t)
allresults <- vector(mode="list",length=t)
allmodels <- vector(mode="list",length=t)
labelorder <- vector(mode="list",length=t)
for (k in 1:t){
set.seed(k)
results <- data.frame(data.frame(matrix(vector(), 810, 20, dimnames=list(c(), col))))
##Process labels
#currently iterative labeling for both trail and test
labels <- data[,70:73]
#shuffles labels
labels <- t(apply(labels,1,sample))
labelorder[[k]] = apply(labels,c(1,2),rescale)
#this may not be perfect since the actual labels
#are rescaled after the mode is taken
#takes the mode for each iteration
labels <- cbind(labels[,1],apply(labels[,1:2],1,mode),
apply(labels[,1:3],1,mode),apply(labels,1,mode))
labels <- apply(labels,c(1,2),rescale)
results[1:4] <- labels
## Label tracker
label.tracker <- rep(1,nrow(labels))
labelsum <- list()
#Separate training, testing and valid
index <- bal_strat(labels)
#Get image features
train = NULL
test = NULL
valid = NULL
models = vector(mode="list",length=4)
train$img <- as.matrix(img_fs[index$train,])
test$img <- as.matrix(img_fs[index$test,])
valid$img <- as.matrix(img_fs[index$valid,])
results[index$train, "Set"] <- "train"
results[index$test, "Set"] <- "test"
results[index$valid, "Set"] <- "valid"
##Iterations
for(r in 1:4)
{
set.seed(r)
#Different iterative label vector for each iteration
iterlabel <- label.selector(labels,label.tracker)
results[paste("I", r, ".Label", sep = "")] <- iterlabel
train$iterl <- iterlabel[index$train]
test$iterl <- iterlabel[index$test]
valid$iterl <- iterlabel[index$valid]
#Make dataframes work for decision trees
train$data <- data.frame(cbind(train$iterl, train$img))
colnames(train$data)[1] <- "label"
test$data <- data.frame(cbind(test$iterl, test$img))
colnames(test$data)[1] <- "label"
valid$data <- data.frame(cbind(valid$iterl, valid$img))
colnames(valid$data)[1] <- "label"
#THIS IS WHERE CLASSIFICATION ACTUALLY HAPPENS
model <- rpart(formula, method = "class", data = train$data, control = ics[r])
models[[r]] <- model
results[paste("I", r, ".Pred", sep = "")] <-
as.integer(predict(model, img_fs, type="class"))
#sum labels at used indices
labelsum[[r]] = sum(label.tracker[c(index$train, index$test, index$valid)])
## Update the label tracker
if(r!=4)
{
miss.iter <- which(results[,paste("I", r, ".Pred", sep = "")]!=
results[,paste("I", r, ".Label", sep = "")])
label.tracker[miss.iter] <- label.tracker[miss.iter]+1
results[paste("I", r, ".Label.Num", sep = "")] <- label.tracker
}
}
#Comparison Consensus Classification
for(a in 1:4){
#Different iterative label vector for each iteration
conslabel <- label.selector(labels,rep(a, times = length(labels[,1])))
train$data <- data.frame(cbind(conslabel[index$train], train$img))
colnames(train$data)[1] <- "label"
model <- rpart(formula, method = "class", data = train$data, control = ics[a+4])
results[paste("A", a, ".Pred", sep = "")] <-
as.integer(predict(model, img_fs, type="class"))
models[[a+4]] = model
}
allaccs[[k]] = calcacc(results, index, g=8)
allmodels[[k]] = models
allresults[[k]] = results
setTxtProgressBar(pb, k)
}
test4accs <- (lapply(allaccs, function(x) x["Test", "I4"]))
deviance <- (lapply(test4accs, function(x, y = mean(as.numeric(test4accs))) abs(x-y)))
best.trial <- max(which(deviance==min(as.numeric(deviance))))
View(allresults[[best.trial]])
best = allresults[[best.trial]]
save(best, file = "best.Rda")
bestorder = labelorder[[best.trial]]
save(bestorder, file = "bestorder.Rda")
agg  = avgacc(allaccs)
View(agg)
for (i in 1:8){
png(paste("tree", i, ".png", sep = ""))
if (i >=5) {m = paste("Non-Selective Tree", i-4)
}else{ m = paste("Selective Tree", i)
}
tree = allmodels[[best.trial]][[i]]
rpart.plot(tree, under = TRUE, extra = 1,
box.col=c("palegreen3", "yellow", "indianred2")[tree$frame$yval],
main = m)
dev.off()
}
pdf("selectiveTrees.pdf")
par(mfrow=c(2,2))
for (i in 1:4){
c=.75
tree = allmodels[[best.trial]][[i]]
rpart.plot(tree, under = TRUE, extra = 1,
box.col=c("palegreen3", "yellow", "indianred2")[tree$frame$yval],
main = paste("Selective Tree", i), cex =c)
}
dev.off()
pdf("nonselectiveTrees.pdf")
par(mfrow=c(2,2))
for (i in 5:8){
c=.75
tree = allmodels[[best.trial]][[i]]
rpart.plot(tree, under = TRUE, extra =1,
box.col=c("palegreen3", "yellow", "indianred2")[tree$frame$yval],
main = paste("Non-Selective Tree", i-4), cex = c)
}
dev.off()
## Loading add-on packages
pack.names <- c("rpart","rpart.plot", "pROC", "caret", "RWeka", "ROCR")
require(plyr)
sapply(pack.names,library,character.only=TRUE)
sapply(pack.names,require,character.only=TRUE)
##Formula for decision tree with all image features
formula = as.formula("label ~ markov1 + markov2 + markov3 + markov4 + markov5 +
SDIntensityBG + IntensityDifference + avg.gabor.mean + avg.gabor.SD + Energy + Homogeneity + Entropy +
thirdordermoment + Inversevariance + Sumaverage + Variance + Clustertendency + MaxProbability +
Circularity + Compactness + Eccentricity + Solidity + Extent + RadialDistanceSD + SecondMoment +
Area + ConvexArea + Perimeter + ConvexPerimeter + EquivDiameter + MajorAxisLength +
MinorAxisLength")
label.selector <- function(x,index)
{
x <- as.vector(t(x))
value <- x[seq(0,4*(length(index)-1),4)+index]
return(value)
}
mode <- function(x)
{
tabSmpl<-tabulate(x)
ifelse((sum(tabSmpl == max(tabSmpl))>1),ceiling(mean(x)),which(tabSmpl== max(tabSmpl)))
}
rescale <- function(x)
{
value <- ifelse(x==1|x==2,1, ifelse( x==3, 2, 3))
return(value)
}
#1 and 2 are benign, 3 is malignant for ROC
rescale1 <- function(x)
{
value <- ifelse(x==1|x==2,0, 1)
return(value)
}
#1 is benign, 2&3 are malignant
rescale3 <- function(x)
{
value <- ifelse(x==2|x==3,1, 0)
return(value)
}
#Only works for this specific dataset
Avg.Gabor <- function( dataset )
{
gabor.features <- dataset[, 19:42]
avg.gabor.mean <- (gabor.features$gabormean_0_0 + gabor.features$gabormean_0_1 + gabor.features$gabormean_0_2 +
gabor.features$gabormean_1_0 + gabor.features$gabormean_1_1 + gabor.features$gabormean_1_2 +
gabor.features$gabormean_2_0 + gabor.features$gabormean_2_1 + gabor.features$gabormean_2_2 +
gabor.features$gabormean_3_0 + gabor.features$gabormean_3_1 + gabor.features$gabormean_3_2)/12
avg.gabor.SD <- (gabor.features$gaborSD_0_0 + gabor.features$gaborSD_0_1 + gabor.features$gaborSD_0_2
+ gabor.features$gaborSD_1_0 + gabor.features$gaborSD_1_1 + gabor.features$gaborSD_1_2
+ gabor.features$gaborSD_2_0 + gabor.features$gaborSD_2_1 + gabor.features$gaborSD_2_2
+ gabor.features$gaborSD_3_0 + gabor.features$gaborSD_3_1 + gabor.features$gaborSD_3_2)/12
avg.gabor.features <- data.frame(avg.gabor.mean, avg.gabor.SD)
return(avg.gabor.features)
}
##Only works for this specific dataset
bal_strat <- function(labels){
##Balance
ones <- which(labels[,4]==1) #201 24.8%
twos <- which(labels[,4]==2) #341 42.1%
threes <- which(labels[,4]==3) #268 33.1%
#twos will be slightly undersampled
#so that they don't represent more than
#40% of the cases or 324 total
#793 is new total case number
##Stratify 60% training, 30% testing, 10% validation
train.ones <- sample(201, 121, replace=FALSE)
train.twos <- sample(341, 205, replace=FALSE)
train.threes <- sample(268, 161, replace=FALSE)
train.index <- c(ones[train.ones], twos[train.twos], threes[train.threes])
test.ones <- sample(seq(1:201)[-train.ones], 60, replace=FALSE)
test.twos <- sample(seq(1:341)[-train.twos], 102, replace=FALSE)
test.threes <- sample(seq(1:268)[-train.threes], 80, replace=FALSE)
test.index <- c(ones[test.ones], twos[test.twos], threes[test.threes])
valid.ones <- sample(seq(1:201)[-c(train.ones, test.ones)], 20,replace=FALSE)
valid.twos <- sample(seq(1:341)[-c(train.twos, test.twos)], 34, replace=FALSE)
valid.threes <- sample(seq(1:268)[-c(train.threes, test.threes)], 27, replace=FALSE)
valid.index <- c(ones[valid.ones], twos[valid.twos], threes[valid.threes])
index = NULL
index$train = as.numeric(train.index)
index$test = as.numeric(test.index)
index$valid = as.numeric(valid.index)
return (index)
}
#Accuracies
calcacc <- function (results, index, g){
d = list(c("Train", "Test", "Valid"),
rep(c(paste("I", 1:4,sep = ""), paste("M", 1:4,sep = ""),
paste("A", 1:4,sep = "")), each =1))
table <- data.frame(data.frame(matrix(vector(), 3, 12,dimnames=d)))
ii=1
for(ii in 1:g){
if(ii < 5){
miss.iter <- which(results[,paste("I", ii, ".Pred", sep = "")]!=
results[,paste("I", ii, ".Label", sep = "")])
miss.mode <- which(results[,paste("I", ii, ".Pred", sep = "")]!=
results[,"Max.Mode"])
table["Train", paste("I", ii,sep = "")] <-
1-length(which(results[miss.iter, "Set"] == "train"))/length(index$train)
table["Test", paste("I", ii,sep = "")] <-
1-length(which(results[miss.iter, "Set"] == "test"))/length(index$test)
table["Valid", paste("I", ii,sep = "")] <-
1-length(which(results[miss.iter, "Set"] == "valid"))/length(index$valid)
table["Train", paste("M", ii,sep = "")] <-
1-length(which(results[miss.mode, "Set"] == "train"))/length(index$train)
table["Test", paste("M", ii,sep = "")] <-
1-length(which(results[miss.mode, "Set"] == "test"))/length(index$test)
table["Valid", paste("M", ii,sep = "")] <-
1-length(which(results[miss.mode, "Set"] == "valid"))/length(index$valid)
} else {
miss.mode <- which(results[,paste("A", (ii-4), ".Pred", sep = "")]!=
labels[,ii-4])
table["Train", paste("A", (ii-4),sep = "")] <-
1-length(which(results[miss.mode, "Set"] == "train"))/length(index$train)
table["Test",paste("A", (ii-4),sep = "")] <-
1-length(which(results[miss.mode, "Set"] == "test"))/length(index$test)
table["Valid", paste("A", (ii-4),sep = "")] <-
1-length(which(results[miss.mode, "Set"] == "valid"))/length(index$valid)
}
}
return (table)
}
ms = seq(10, 250, 20)
mb = seq(2, 60, 4)
tunecontrols = expand.grid("minsplit" = ms, "minbucket" = mb, "cp" = 0.01,
"maxcompete" = 4,  "maxsurrogate"	= 5,
"usesurrogate" = 2, "surrogatestyle"	=0,
"maxdepth" =50)
#Controls
ics = list(rpart.control(minsplit = 170, minbucket= 6),
rpart.control(minsplit = 170, minbucket= 6),
rpart.control(minsplit = 50, minbucket= 6),
rpart.control(minsplit = 110, minbucket= 6),
rpart.control(minsplit = 250, minbucket= 58),
rpart.control(minsplit = 210, minbucket= 6),
rpart.control(minsplit = 130, minbucket= 6),
rpart.control(minsplit = 150, minbucket= 6))
ehcontrols = c(rpart.control(minsplit = 510, minbucket= 2, cp = 0.01),
rpart.control(minsplit = 510, minbucket= 2, cp = 0.01),
rpart.control(minsplit = 510, minbucket= 2, cp = 0.01),
rpart.control(minsplit = 510, minbucket= 2, cp = 0.01),
rpart.control(minsplit = 510, minbucket= 2, cp = 0.01))
avgacc <- function(allaccs) {
yiah <- data.frame(
data.frame(matrix(vector(), 6, 8,
dimnames=list(c("TrainAcc","TrainErr", "TestAcc","TestErr",
"ValidAcc", "ValidErr"), c ("I1","I2","I3","I4",
"A1", "A2", "A3", "A4")))))
for (i in 1:3){
yiah[(i*2)-1,"I1"] = summary(sapply(allaccs, function (x) x[i, "I1"]))["Mean"]
yiah[(i*2)-1,"I2"] = summary(sapply(allaccs, function (x) x[i, "I2"]))["Mean"]
yiah[(i*2)-1,"I3"] = summary(sapply(allaccs, function (x) x[i, "I3"]))["Mean"]
yiah[(i*2)-1,"I4"] = summary(sapply(allaccs, function (x) x[i, "I4"]))["Mean"]
yiah[(i*2)-1,"A1"] = summary(sapply(allaccs, function (x) x[i, "A1"]))["Mean"]
yiah[(i*2)-1,"A2"] = summary(sapply(allaccs, function (x) x[i, "A2"]))["Mean"]
yiah[(i*2)-1,"A3"] = summary(sapply(allaccs, function (x) x[i, "A3"]))["Mean"]
yiah[(i*2)-1,"A4"] = summary(sapply(allaccs, function (x) x[i, "A4"]))["Mean"]
yiah[i*2,"I1"] = aerror(sapply(allaccs, function (x) x[i, "I1"]))
yiah[i*2,"I2"] = aerror(sapply(allaccs, function (x) x[i, "I2"]))
yiah[i*2,"I3"] = aerror(sapply(allaccs, function (x) x[i, "I3"]))
yiah[i*2,"I4"] = aerror(sapply(allaccs, function (x) x[i, "I4"]))
yiah[i*2,"A1"] = aerror(sapply(allaccs, function (x) x[i, "A1"]))
yiah[i*2,"A2"] = aerror(sapply(allaccs, function (x) x[i, "A2"]))
yiah[i*2,"A3"] = aerror(sapply(allaccs, function (x) x[i, "A3"]))
yiah[i*2,"A4"] = aerror(sapply(allaccs, function (x) x[i, "A4"]))
}
return (yiah)
}
aerror <- function(x) {
qt(0.975,df=length(x)-1)*sd(x)/sqrt(length(x))}
##Absolutely necessary to run initialization BEFORE this file
##Import data
data <- read.csv("LIDC dataset with full annotations.csv",header=TRUE)
img_fs <- data[,c(5:18, 43:69)]
img_fs <- data.frame(img_fs, Avg.Gabor(data))
#Df for results
col <-  c("Mode 1", "Mode 2", "Mode 3", "Max Mode", "Set",
"I1 Label", "I1 Pred", "I1 Label Num", "I2 Label",
"I2 Pred","I2 Label Num", "I3 Label", "I3 Pred",
"I3 Label Num", "I4 Label", "I4 Pred", "A1.Pred",
"A2.Pred","A3.Pred","A4.Pred")
cont = rpart.control(minsplit = 250, minbucket= 58, maxdepth = 5)
t = 20
pb <- txtProgressBar(min = 0, max = t, style = 3)
allaccs <- vector(mode="list",length=t)
allresults <- vector(mode="list",length=t)
allmodels <- vector(mode="list",length=t)
labelorder <- vector(mode="list",length=t)
for (k in 1:t){
set.seed(k)
results <- data.frame(data.frame(matrix(vector(), 810, 20, dimnames=list(c(), col))))
##Process labels
#currently iterative labeling for both trail and test
labels <- data[,70:73]
#shuffles labels
labels <- t(apply(labels,1,sample))
labelorder[[k]] = apply(labels,c(1,2),rescale)
#this may not be perfect since the actual labels
#are rescaled after the mode is taken
#takes the mode for each iteration
labels <- cbind(labels[,1],apply(labels[,1:2],1,mode),
apply(labels[,1:3],1,mode),apply(labels,1,mode))
labels <- apply(labels,c(1,2),rescale)
results[1:4] <- labels
## Label tracker
label.tracker <- rep(1,nrow(labels))
labelsum <- list()
#Separate training, testing and valid
index <- bal_strat(labels)
#Get image features
train = NULL
test = NULL
valid = NULL
models = vector(mode="list",length=4)
train$img <- as.matrix(img_fs[index$train,])
test$img <- as.matrix(img_fs[index$test,])
valid$img <- as.matrix(img_fs[index$valid,])
results[index$train, "Set"] <- "train"
results[index$test, "Set"] <- "test"
results[index$valid, "Set"] <- "valid"
##Iterations
for(r in 1:4)
{
set.seed(r)
#Different iterative label vector for each iteration
iterlabel <- label.selector(labels,label.tracker)
results[paste("I", r, ".Label", sep = "")] <- iterlabel
train$iterl <- iterlabel[index$train]
test$iterl <- iterlabel[index$test]
valid$iterl <- iterlabel[index$valid]
#Make dataframes work for decision trees
train$data <- data.frame(cbind(train$iterl, train$img))
colnames(train$data)[1] <- "label"
test$data <- data.frame(cbind(test$iterl, test$img))
colnames(test$data)[1] <- "label"
valid$data <- data.frame(cbind(valid$iterl, valid$img))
colnames(valid$data)[1] <- "label"
#THIS IS WHERE CLASSIFICATION ACTUALLY HAPPENS
model <- rpart(formula, method = "class", data = train$data, control = ics[r])
models[[r]] <- model
results[paste("I", r, ".Pred", sep = "")] <-
as.integer(predict(model, img_fs, type="class"))
#sum labels at used indices
labelsum[[r]] = sum(label.tracker[c(index$train, index$test, index$valid)])
## Update the label tracker
if(r!=4)
{
miss.iter <- which(results[,paste("I", r, ".Pred", sep = "")]!=
results[,paste("I", r, ".Label", sep = "")])
label.tracker[miss.iter] <- label.tracker[miss.iter]+1
results[paste("I", r, ".Label.Num", sep = "")] <- label.tracker
}
}
#Comparison Consensus Classification
for(a in 1:4){
#Different iterative label vector for each iteration
conslabel <- label.selector(labels,rep(a, times = length(labels[,1])))
train$data <- data.frame(cbind(conslabel[index$train], train$img))
colnames(train$data)[1] <- "label"
model <- rpart(formula, method = "class", data = train$data, control = ics[a+4])
results[paste("A", a, ".Pred", sep = "")] <-
as.integer(predict(model, img_fs, type="class"))
models[[a+4]] = model
}
allaccs[[k]] = calcacc(results, index, g=8)
allmodels[[k]] = models
allresults[[k]] = results
setTxtProgressBar(pb, k)
}
test4accs <- (lapply(allaccs, function(x) x["Test", "I4"]))
deviance <- (lapply(test4accs, function(x, y = mean(as.numeric(test4accs))) abs(x-y)))
best.trial <- max(which(deviance==min(as.numeric(deviance))))
View(allresults[[best.trial]])
best = allresults[[best.trial]]
save(best, file = "best.Rda")
bestorder = labelorder[[best.trial]]
save(bestorder, file = "bestorder.Rda")
agg  = avgacc(allaccs)
View(agg)
for (i in 1:8){
png(paste("tree", i, ".png", sep = ""))
if (i >=5) {m = paste("Non-Selective Tree", i-4)
}else{ m = paste("Selective Tree", i)
}
tree = allmodels[[best.trial]][[i]]
rpart.plot(tree, under = TRUE, extra = 1,
box.col=c("palegreen3", "yellow", "indianred2")[tree$frame$yval],
main = m)
dev.off()
}
pdf("selectiveTrees.pdf")
par(mfrow=c(2,2))
for (i in 1:4){
c=.75
tree = allmodels[[best.trial]][[i]]
rpart.plot(tree, under = TRUE, extra = 2,
box.col=c("palegreen3", "yellow", "indianred2")[tree$frame$yval],
main = paste("Selective Tree", i), cex =c)
}
dev.off()
pdf("nonselectiveTrees.pdf")
par(mfrow=c(2,2))
for (i in 5:8){
c=.75
tree = allmodels[[best.trial]][[i]]
rpart.plot(tree, under = TRUE, extra =2,
box.col=c("palegreen3", "yellow", "indianred2")[tree$frame$yval],
main = paste("Non-Selective Tree", i-4), cex = c)
}
dev.off()
